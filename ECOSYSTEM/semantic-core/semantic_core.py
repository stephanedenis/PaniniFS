#!/usr/bin/env python3
"""
ğŸ§  PANINI SEMANTIC CORE
Primitives sÃ©mantiques universelles pour l'IA moderne

GitHub: https://github.com/stephanedenis/PaniniFS-SemanticCore
"""

import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
import time

class UniversalSemanticProcessor:
    """
    Processeur sÃ©mantique universel basÃ© sur les primitives dÃ©couvertes
    """
    
    def __init__(self, model_name="all-MiniLM-L6-v2"):
        self.model = SentenceTransformer(model_name)
        self.semantic_cache = {}
        self.universal_patterns = {}
        
    def extract_semantic_primitives(self, texts: List[str]) -> Dict[str, Any]:
        """
        Extraction des primitives sÃ©mantiques universelles
        
        Returns:
            Dict avec embeddings, clusters, patterns universels
        """
        
        # GÃ©nÃ©ration embeddings
        embeddings = self.model.encode(texts)
        
        # DÃ©tection patterns universels
        patterns = self._detect_universal_patterns(embeddings, texts)
        
        # Clustering sÃ©mantique
        clusters = self._semantic_clustering(embeddings, texts)
        
        return {
            'embeddings': embeddings,
            'patterns': patterns,
            'clusters': clusters,
            'universality_score': self._calculate_universality(patterns),
            'metadata': {
                'model': self.model,
                'texts_count': len(texts),
                'processing_time': time.time()
            }
        }
    
    def _detect_universal_patterns(self, embeddings: np.ndarray, texts: List[str]) -> Dict:
        """DÃ©tection des patterns universellement applicables"""
        
        # Calcul similaritÃ©s
        similarities = cosine_similarity(embeddings)
        
        # Identification concepts publics vs privÃ©s
        public_concepts = []
        private_concepts = []
        
        for i, text in enumerate(texts):
            avg_similarity = np.mean(similarities[i])
            
            if avg_similarity > 0.7:  # TrÃ¨s similaire = concept universel
                public_concepts.append({
                    'text': text,
                    'embedding': embeddings[i],
                    'universality': avg_similarity
                })
            else:  # SpÃ©cifique = concept privÃ©
                private_concepts.append({
                    'text': text,
                    'embedding': embeddings[i],
                    'specificity': 1 - avg_similarity
                })
        
        return {
            'public_concepts': public_concepts,
            'private_concepts': private_concepts,
            'public_ratio': len(public_concepts) / len(texts)
        }
    
    def _semantic_clustering(self, embeddings: np.ndarray, texts: List[str]) -> Dict:
        """Clustering sÃ©mantique intelligent"""
        from sklearn.cluster import DBSCAN
        
        # Clustering DBSCAN pour densitÃ© variable
        clustering = DBSCAN(eps=0.3, min_samples=2, metric='cosine')
        cluster_labels = clustering.fit_predict(embeddings)
        
        # Organisation par clusters
        clusters = {}
        for i, label in enumerate(cluster_labels):
            if label not in clusters:
                clusters[label] = []
            clusters[label].append({
                'text': texts[i],
                'embedding': embeddings[i],
                'index': i
            })
        
        return clusters
    
    def _calculate_universality(self, patterns: Dict) -> float:
        """Score d'universalitÃ© des patterns dÃ©tectÃ©s"""
        return patterns['public_ratio']
    
    def quick_semantic_search(self, query: str, corpus: List[str], top_k: int = 5) -> List[Dict]:
        """
        Recherche sÃ©mantique rapide optimisÃ©e
        """
        
        # Embedding requÃªte
        query_embedding = self.model.encode([query])
        
        # Embeddings corpus (avec cache)
        corpus_key = str(hash(str(corpus)))
        if corpus_key in self.semantic_cache:
            corpus_embeddings = self.semantic_cache[corpus_key]
        else:
            corpus_embeddings = self.model.encode(corpus)
            self.semantic_cache[corpus_key] = corpus_embeddings
        
        # Calcul similaritÃ©s
        similarities = cosine_similarity(query_embedding, corpus_embeddings)[0]
        
        # Top-K rÃ©sultats
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            results.append({
                'text': corpus[idx],
                'similarity': similarities[idx],
                'index': idx,
                'universality': self._estimate_concept_universality(corpus[idx])
            })
        
        return results
    
    def _estimate_concept_universality(self, text: str) -> float:
        """Estimation rapide universalitÃ© d'un concept"""
        
        # Heuristiques basÃ©es sur la dÃ©couverte des primitives
        universal_indicators = [
            'search', 'find', 'process', 'analyze', 'optimize',
            'create', 'generate', 'transform', 'validate', 'execute'
        ]
        
        score = 0
        for indicator in universal_indicators:
            if indicator.lower() in text.lower():
                score += 0.1
        
        return min(score, 1.0)

# ğŸ§ª DEMO SYSTÃˆME
def demo_semantic_core():
    print("ğŸ§  DEMO SEMANTIC CORE")
    print("=" * 50)
    
    processor = UniversalSemanticProcessor()
    
    # Corpus test
    texts = [
        "semantic search in documents",
        "find relevant information quickly", 
        "process natural language efficiently",
        "my private database credentials",
        "internal company meeting notes",
        "optimize machine learning models"
    ]
    
    # Extraction primitives
    print("\nğŸ” Extraction Primitives SÃ©mantiques...")
    primitives = processor.extract_semantic_primitives(texts)
    
    print(f"âœ… Concepts publics: {len(primitives['patterns']['public_concepts'])}")
    print(f"âœ… Concepts privÃ©s: {len(primitives['patterns']['private_concepts'])}")
    print(f"âœ… Score universalitÃ©: {primitives['universality_score']:.2f}")
    
    # Recherche sÃ©mantique
    print("\nğŸ” Recherche SÃ©mantique...")
    query = "search for information"
    results = processor.quick_semantic_search(query, texts, top_k=3)
    
    for i, result in enumerate(results):
        print(f"{i+1}. {result['text']} (sim: {result['similarity']:.3f}, univ: {result['universality']:.2f})")
    
    print("\nğŸ Demo completed!")

if __name__ == "__main__":
    demo_semantic_core()
